Sequential:
nano src/sequential_matrix.c
#include <stdio.h>
#include <stdlib.h>
#include <time.h>

void matrix_multiply(double **A, double **B, double **C, int n) {
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            C[i][j] = 0;
            for (int k = 0; k < n; k++) {
                C[i][j] += A[i][k] * B[k][j];
            }
        }
    }
}

double** allocate_matrix(int n) {
    double **matrix = (double**)malloc(n * sizeof(double*));
    for (int i = 0; i < n; i++) {
        matrix[i] = (double*)malloc(n * sizeof(double));
    }
    return matrix;
}

void initialize_matrix(double **matrix, int n) {
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            matrix[i][j] = (double)(rand() % 10);
        }
    }
}

void free_matrix(double **matrix, int n) {
    for (int i = 0; i < n; i++) {
        free(matrix[i]);
    }
    free(matrix);
}

int main(int argc, char *argv[]) {
    if (argc != 2) {
        printf("Usage: %s <matrix_size>\n", argv[0]);
        return 1;
    }
    
    int n = atoi(argv[1]);
    printf("Sequential Matrix Multiplication: %dx%d\n", n, n);
    
    double **A = allocate_matrix(n);
    double **B = allocate_matrix(n);
    double **C = allocate_matrix(n);
    
    srand(time(NULL));
    initialize_matrix(A, n);
    initialize_matrix(B, n);
    
    clock_t start = clock();
    matrix_multiply(A, B, C, n);
    clock_t end = clock();
    
    double time_taken = ((double)(end - start)) / CLOCKS_PER_SEC;
    printf("Time taken: %.6f seconds\n", time_taken);
    
    free_matrix(A, n);
    free_matrix(B, n);
    free_matrix(C, n);
    
    return 0;
}




nano src/pthread_matrix.c
#include <stdio.h>
#include <stdlib.h>
#include <pthread.h>
#include <time.h>

typedef struct {
    double **A;
    double **B;
    double **C;
    int n;
    int start_row;
    int end_row;
} ThreadData;

void* matrix_multiply_thread(void* arg) {
    ThreadData *data = (ThreadData*)arg;
    for (int i = data->start_row; i < data->end_row; i++) {
        for (int j = 0; j < data->n; j++) {
            data->C[i][j] = 0;
            for (int k = 0; k < data->n; k++) {
                data->C[i][j] += data->A[i][k] * data->B[k][j];
            }
        }
    }
    return NULL;
}

double** allocate_matrix(int n) {
    double **matrix = (double**)malloc(n * sizeof(double*));
    for (int i = 0; i < n; i++) {
        matrix[i] = (double*)malloc(n * sizeof(double));
    }
    return matrix;
}

void initialize_matrix(double **matrix, int n) {
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            matrix[i][j] = (double)(rand() % 10);
        }
    }
}

void free_matrix(double **matrix, int n) {
    for (int i = 0; i < n; i++) {
        free(matrix[i]);
    }
    free(matrix);
}

int main(int argc, char *argv[]) {
    if (argc != 3) {
        printf("Usage: %s <matrix_size> <num_threads>\n", argv[0]);
        return 1;
    }
    
    int n = atoi(argv[1]);
    int num_threads = atoi(argv[2]);
    printf("Pthread Matrix Multiplication: %dx%d with %d threads\n", n, n, num_threads);
    
    double **A = allocate_matrix(n);
    double **B = allocate_matrix(n);
    double **C = allocate_matrix(n);
    
    srand(time(NULL));
    initialize_matrix(A, n);
    initialize_matrix(B, n);
    
    pthread_t threads[num_threads];
    ThreadData thread_data[num_threads];
    int rows_per_thread = n / num_threads;
    
    clock_t start = clock();
    
    for (int i = 0; i < num_threads; i++) {
        thread_data[i].A = A;
        thread_data[i].B = B;
        thread_data[i].C = C;
        thread_data[i].n = n;
        thread_data[i].start_row = i * rows_per_thread;
        thread_data[i].end_row = (i == num_threads - 1) ? n : (i + 1) * rows_per_thread;
        pthread_create(&threads[i], NULL, matrix_multiply_thread, &thread_data[i]);
    }
    
    for (int i = 0; i < num_threads; i++) {
        pthread_join(threads[i], NULL);
    }
    
    clock_t end = clock();
    double time_taken = ((double)(end - start)) / CLOCKS_PER_SEC;
    printf("Time taken: %.6f seconds\n", time_taken);
    
    free_matrix(A, n);
    free_matrix(B, n);
    free_matrix(C, n);
    
    return 0;
}






nano src/openmp_matrix.c
#include <stdio.h>
#include <stdlib.h>
#include <omp.h>
#include <time.h>

void matrix_multiply(double **A, double **B, double **C, int n) {
    #pragma omp parallel for collapse(2)
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            C[i][j] = 0;
            for (int k = 0; k < n; k++) {
                C[i][j] += A[i][k] * B[k][j];
            }
        }
    }
}

double** allocate_matrix(int n) {
    double **matrix = (double**)malloc(n * sizeof(double*));
    for (int i = 0; i < n; i++) {
        matrix[i] = (double*)malloc(n * sizeof(double));
    }
    return matrix;
}

void initialize_matrix(double **matrix, int n) {
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            matrix[i][j] = (double)(rand() % 10);
        }
    }
}

void free_matrix(double **matrix, int n) {
    for (int i = 0; i < n; i++) {
        free(matrix[i]);
    }
    free(matrix);
}

int main(int argc, char *argv[]) {
    if (argc != 3) {
        printf("Usage: %s <matrix_size> <num_threads>\n", argv[0]);
        return 1;
    }
    
    int n = atoi(argv[1]);
    int num_threads = atoi(argv[2]);
    omp_set_num_threads(num_threads);
    
    printf("OpenMP Matrix Multiplication: %dx%d with %d threads\n", n, n, num_threads);
    
    double **A = allocate_matrix(n);
    double **B = allocate_matrix(n);
    double **C = allocate_matrix(n);
    
    srand(time(NULL));
    initialize_matrix(A, n);
    initialize_matrix(B, n);
    
    double start = omp_get_wtime();
    matrix_multiply(A, B, C, n);
    double end = omp_get_wtime();
    
    printf("Time taken: %.6f seconds\n", end - start);
    
    free_matrix(A, n);
    free_matrix(B, n);
    free_matrix(C, n);
    
    return 0;
}







nano src/mpi_matrix.c
#include <stdio.h>
#include <stdlib.h>
#include <mpi.h>
#include <time.h>

double** allocate_matrix(int rows, int cols) {
    double **matrix = (double**)malloc(rows * sizeof(double*));
    for (int i = 0; i < rows; i++) {
        matrix[i] = (double*)malloc(cols * sizeof(double));
    }
    return matrix;
}

void initialize_matrix(double **matrix, int rows, int cols) {
    for (int i = 0; i < rows; i++) {
        for (int j = 0; j < cols; j++) {
            matrix[i][j] = (double)(rand() % 10);
        }
    }
}

void free_matrix(double **matrix, int rows) {
    for (int i = 0; i < rows; i++) {
        free(matrix[i]);
    }
    free(matrix);
}

int main(int argc, char *argv[]) {
    int rank, size;
    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);
    
    if (argc != 2) {
        if (rank == 0) {
            printf("Usage: mpirun -np <num_processes> %s <matrix_size>\n", argv[0]);
        }
        MPI_Finalize();
        return 1;
    }
    
    int n = atoi(argv[1]);
    int rows_per_process = n / size;
    
    double **A = NULL;
    double **B = allocate_matrix(n, n);
    double **C_local = allocate_matrix(rows_per_process, n);
    double **A_local = allocate_matrix(rows_per_process, n);
    
    if (rank == 0) {
        A = allocate_matrix(n, n);
        srand(time(NULL));
        initialize_matrix(A, n, n);
        initialize_matrix(B, n, n);
        
        printf("MPI Matrix Multiplication: %dx%d with %d processes\n", n, n, size);
    }
    
    // Broadcast matrix B to all processes
    for (int i = 0; i < n; i++) {
        MPI_Bcast(B[i], n, MPI_DOUBLE, 0, MPI_COMM_WORLD);
    }
    
    // Scatter rows of A
    if (rank == 0) {
        for (int i = 0; i < rows_per_process; i++) {
            for (int j = 0; j < n; j++) {
                A_local[i][j] = A[i][j];
            }
        }
        for (int p = 1; p < size; p++) {
            for (int i = 0; i < rows_per_process; i++) {
                MPI_Send(A[p * rows_per_process + i], n, MPI_DOUBLE, p, 0, MPI_COMM_WORLD);
            }
        }
    } else {
        for (int i = 0; i < rows_per_process; i++) {
            MPI_Recv(A_local[i], n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        }
    }
    
    double start_time = MPI_Wtime();
    
    // Local computation
    for (int i = 0; i < rows_per_process; i++) {
        for (int j = 0; j < n; j++) {
            C_local[i][j] = 0;
            for (int k = 0; k < n; k++) {
                C_local[i][j] += A_local[i][k] * B[k][j];
            }
        }
    }
    
    double end_time = MPI_Wtime();
    
    // Gather results
    if (rank == 0) {
        double **C = allocate_matrix(n, n);
        for (int i = 0; i < rows_per_process; i++) {
            for (int j = 0; j < n; j++) {
                C[i][j] = C_local[i][j];
            }
        }
        for (int p = 1; p < size; p++) {
            for (int i = 0; i < rows_per_process; i++) {
                MPI_Recv(C[p * rows_per_process + i], n, MPI_DOUBLE, p, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
            }
        }
        
        printf("Time taken: %.6f seconds\n", end_time - start_time);
        free_matrix(C, n);
        free_matrix(A, n);
    } else {
        for (int i = 0; i < rows_per_process; i++) {
            MPI_Send(C_local[i], n, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD);
        }
    }
    
    free_matrix(B, n);
    free_matrix(C_local, rows_per_process);
    free_matrix(A_local, rows_per_process);
    
    MPI_Finalize();
    return 0;
}









nano Makefile
CC = gcc
MPICC = mpicc
CFLAGS = -O3 -Wall
PTHREAD_FLAGS = -pthread
OPENMP_FLAGS = -fopenmp

SRC_DIR = src
BUILD_DIR = build

SEQUENTIAL = $(BUILD_DIR)/sequential_matrix
PTHREAD = $(BUILD_DIR)/pthread_matrix
OPENMP = $(BUILD_DIR)/openmp_matrix
MPI = $(BUILD_DIR)/mpi_matrix

all: $(BUILD_DIR) $(SEQUENTIAL) $(PTHREAD) $(OPENMP) $(MPI)

$(BUILD_DIR):
	mkdir -p $(BUILD_DIR)

$(SEQUENTIAL): $(SRC_DIR)/sequential_matrix.c
	$(CC) $(CFLAGS) $< -o $@

$(PTHREAD): $(SRC_DIR)/pthread_matrix.c
	$(CC) $(CFLAGS) $(PTHREAD_FLAGS) $< -o $@

$(OPENMP): $(SRC_DIR)/openmp_matrix.c
	$(CC) $(CFLAGS) $(OPENMP_FLAGS) $< -o $@

$(MPI): $(SRC_DIR)/mpi_matrix.c
	$(MPICC) $(CFLAGS) $< -o $@

clean:
	rm -rf $(BUILD_DIR)

.PHONY: all clean






make





nano run_benchmarks.sh
#!/bin/bash

SIZES=(10 500 1000)
THREADS=4
PROCESSES=4
RESULTS_FILE="results/matrix_results.txt"

echo "Matrix Multiplication Benchmarking Results" > $RESULTS_FILE
echo "==========================================" >> $RESULTS_FILE
echo "" >> $RESULTS_FILE

for SIZE in "${SIZES[@]}"
do
    echo "Testing with matrix size: ${SIZE}x${SIZE}" | tee -a $RESULTS_FILE
    echo "----------------------------------------" | tee -a $RESULTS_FILE
    
    echo "" | tee -a $RESULTS_FILE
    echo "Sequential:" | tee -a $RESULTS_FILE
    ./build/sequential_matrix $SIZE | tee -a $RESULTS_FILE
    
    echo "" | tee -a $RESULTS_FILE
    echo "Pthreads ($THREADS threads):" | tee -a $RESULTS_FILE
    ./build/pthread_matrix $SIZE $THREADS | tee -a $RESULTS_FILE
    
    echo "" | tee -a $RESULTS_FILE
    echo "OpenMP ($THREADS threads):" | tee -a $RESULTS_FILE
    ./build/openmp_matrix $SIZE $THREADS | tee -a $RESULTS_FILE
    
    echo "" | tee -a $RESULTS_FILE
    echo "MPI ($PROCESSES processes):" | tee -a $RESULTS_FILE
    mpirun -np $PROCESSES ./build/mpi_matrix $SIZE | tee -a $RESULTS_FILE
    
    echo "" | tee -a $RESULTS_FILE
    echo "========================================" | tee -a $RESULTS_FILE
    echo "" | tee -a $RESULTS_FILE
done

echo "Benchmarking complete! Results saved to $RESULTS_FILE"




chmod +x run_benchmarks.sh
./run_benchmarks.sh



cat results/matrix_results.txt



Sorting: 
nano src/sequential_sort.c
#include <stdio.h>
#include <stdlib.h>
#include <time.h>
#include <string.h>

void merge(int arr[], int left, int mid, int right) {
    int n1 = mid - left + 1;
    int n2 = right - mid;
    
    int *L = (int*)malloc(n1 * sizeof(int));
    int *R = (int*)malloc(n2 * sizeof(int));
    
    for (int i = 0; i < n1; i++)
        L[i] = arr[left + i];
    for (int j = 0; j < n2; j++)
        R[j] = arr[mid + 1 + j];
    
    int i = 0, j = 0, k = left;
    
    while (i < n1 && j < n2) {
        if (L[i] <= R[j]) {
            arr[k] = L[i];
            i++;
        } else {
            arr[k] = R[j];
            j++;
        }
        k++;
    }
    
    while (i < n1) {
        arr[k] = L[i];
        i++;
        k++;
    }
    
    while (j < n2) {
        arr[k] = R[j];
        j++;
        k++;
    }
    
    free(L);
    free(R);
}

void merge_sort(int arr[], int left, int right) {
    if (left < right) {
        int mid = left + (right - left) / 2;
        merge_sort(arr, left, mid);
        merge_sort(arr, mid + 1, right);
        merge(arr, left, mid, right);
    }
}

int main(int argc, char *argv[]) {
    if (argc != 2) {
        printf("Usage: %s <array_size>\n", argv[0]);
        return 1;
    }
    
    int n = atoi(argv[1]);
    printf("Sequential Merge Sort: %d elements\n", n);
    
    int *arr = (int*)malloc(n * sizeof(int));
    
    srand(time(NULL));
    for (int i = 0; i < n; i++) {
        arr[i] = rand() % 100000;
    }
    
    clock_t start = clock();
    merge_sort(arr, 0, n - 1);
    clock_t end = clock();
    
    double time_taken = ((double)(end - start)) / CLOCKS_PER_SEC;
    printf("Time taken: %.6f seconds\n", time_taken);
    
    free(arr);
    return 0;
}





nano src/pthread_sort.c
#include <stdio.h>
#include <stdlib.h>
#include <pthread.h>
#include <time.h>
#include <string.h>

typedef struct {
    int *arr;
    int left;
    int right;
} ThreadData;

void merge(int arr[], int left, int mid, int right) {
    int n1 = mid - left + 1;
    int n2 = right - mid;
    
    int *L = (int*)malloc(n1 * sizeof(int));
    int *R = (int*)malloc(n2 * sizeof(int));
    
    for (int i = 0; i < n1; i++)
        L[i] = arr[left + i];
    for (int j = 0; j < n2; j++)
        R[j] = arr[mid + 1 + j];
    
    int i = 0, j = 0, k = left;
    
    while (i < n1 && j < n2) {
        if (L[i] <= R[j]) {
            arr[k] = L[i];
            i++;
        } else {
            arr[k] = R[j];
            j++;
        }
        k++;
    }
    
    while (i < n1) {
        arr[k] = L[i];
        i++;
        k++;
    }
    
    while (j < n2) {
        arr[k] = R[j];
        j++;
        k++;
    }
    
    free(L);
    free(R);
}

void merge_sort(int arr[], int left, int right) {
    if (left < right) {
        int mid = left + (right - left) / 2;
        merge_sort(arr, left, mid);
        merge_sort(arr, mid + 1, right);
        merge(arr, left, mid, right);
    }
}

void* parallel_merge_sort(void* arg) {
    ThreadData *data = (ThreadData*)arg;
    merge_sort(data->arr, data->left, data->right);
    return NULL;
}

int main(int argc, char *argv[]) {
    if (argc != 3) {
        printf("Usage: %s <array_size> <num_threads>\n", argv[0]);
        return 1;
    }
    
    int n = atoi(argv[1]);
    int num_threads = atoi(argv[2]);
    printf("Pthread Merge Sort: %d elements with %d threads\n", n, num_threads);
    
    int *arr = (int*)malloc(n * sizeof(int));
    
    srand(time(NULL));
    for (int i = 0; i < n; i++) {
        arr[i] = rand() % 100000;
    }
    
    clock_t start = clock();
    
    pthread_t threads[num_threads];
    ThreadData thread_data[num_threads];
    int chunk_size = n / num_threads;
    
    for (int i = 0; i < num_threads; i++) {
        thread_data[i].arr = arr;
        thread_data[i].left = i * chunk_size;
        thread_data[i].right = (i == num_threads - 1) ? (n - 1) : ((i + 1) * chunk_size - 1);
        pthread_create(&threads[i], NULL, parallel_merge_sort, &thread_data[i]);
    }
    
    for (int i = 0; i < num_threads; i++) {
        pthread_join(threads[i], NULL);
    }
    
    // Merge all sorted chunks
    for (int i = 1; i < num_threads; i++) {
        int left = 0;
        int mid = i * chunk_size - 1;
        int right = (i == num_threads - 1) ? (n - 1) : ((i + 1) * chunk_size - 1);
        merge(arr, left, mid, right);
    }
    
    clock_t end = clock();
    double time_taken = ((double)(end - start)) / CLOCKS_PER_SEC;
    printf("Time taken: %.6f seconds\n", time_taken);
    
    free(arr);
    return 0;
}





nano src/openmp_sort.c
#include <stdio.h>
#include <stdlib.h>
#include <omp.h>
#include <time.h>
#include <string.h>

void merge(int arr[], int left, int mid, int right) {
    int n1 = mid - left + 1;
    int n2 = right - mid;
    
    int *L = (int*)malloc(n1 * sizeof(int));
    int *R = (int*)malloc(n2 * sizeof(int));
    
    for (int i = 0; i < n1; i++)
        L[i] = arr[left + i];
    for (int j = 0; j < n2; j++)
        R[j] = arr[mid + 1 + j];
    
    int i = 0, j = 0, k = left;
    
    while (i < n1 && j < n2) {
        if (L[i] <= R[j]) {
            arr[k] = L[i];
            i++;
        } else {
            arr[k] = R[j];
            j++;
        }
        k++;
    }
    
    while (i < n1) {
        arr[k] = L[i];
        i++;
        k++;
    }
    
    while (j < n2) {
        arr[k] = R[j];
        j++;
        k++;
    }
    
    free(L);
    free(R);
}

void merge_sort(int arr[], int left, int right, int depth) {
    if (left < right) {
        int mid = left + (right - left) / 2;
        
        if (depth > 0) {
            #pragma omp task
            merge_sort(arr, left, mid, depth - 1);
            
            #pragma omp task
            merge_sort(arr, mid + 1, right, depth - 1);
            
            #pragma omp taskwait
        } else {
            merge_sort(arr, left, mid, 0);
            merge_sort(arr, mid + 1, right, 0);
        }
        
        merge(arr, left, mid, right);
    }
}

int main(int argc, char *argv[]) {
    if (argc != 3) {
        printf("Usage: %s <array_size> <num_threads>\n", argv[0]);
        return 1;
    }
    
    int n = atoi(argv[1]);
    int num_threads = atoi(argv[2]);
    omp_set_num_threads(num_threads);
    
    printf("OpenMP Merge Sort: %d elements with %d threads\n", n, num_threads);
    
    int *arr = (int*)malloc(n * sizeof(int));
    
    srand(time(NULL));
    for (int i = 0; i < n; i++) {
        arr[i] = rand() % 100000;
    }
    
    double start = omp_get_wtime();
    
    #pragma omp parallel
    {
        #pragma omp single
        merge_sort(arr, 0, n - 1, 4);
    }
    
    double end = omp_get_wtime();
    printf("Time taken: %.6f seconds\n", end - start);
    
    free(arr);
    return 0;
}




nano Makefile
CC = gcc
CFLAGS = -O3 -Wall
PTHREAD_FLAGS = -pthread
OPENMP_FLAGS = -fopenmp

SRC_DIR = src
BUILD_DIR = build

SEQUENTIAL = $(BUILD_DIR)/sequential_sort
PTHREAD = $(BUILD_DIR)/pthread_sort
OPENMP = $(BUILD_DIR)/openmp_sort

all: $(BUILD_DIR) $(SEQUENTIAL) $(PTHREAD) $(OPENMP)

$(BUILD_DIR):
	mkdir -p $(BUILD_DIR)

$(SEQUENTIAL): $(SRC_DIR)/sequential_sort.c
	$(CC) $(CFLAGS) $< -o $@

$(PTHREAD): $(SRC_DIR)/pthread_sort.c
	$(CC) $(CFLAGS) $(PTHREAD_FLAGS) $< -o $@

$(OPENMP): $(SRC_DIR)/openmp_sort.c
	$(CC) $(CFLAGS) $(OPENMP_FLAGS) $< -o $@

clean:
	rm -rf $(BUILD_DIR)

.PHONY: all clean





nano run_sort_benchmarks.sh
#!/bin/bash

SIZES=(10000 100000 1000000 10000000)
THREADS=4
RESULTS_FILE="results/sorting_results.txt"

echo "Merge Sort Benchmarking Results" > $RESULTS_FILE
echo "===============================" >> $RESULTS_FILE
echo "" >> $RESULTS_FILE

for SIZE in "${SIZES[@]}"
do
    echo "Testing with array size: $SIZE" | tee -a $RESULTS_FILE
    echo "----------------------------------------" | tee -a $RESULTS_FILE
    
    echo "" | tee -a $RESULTS_FILE
    echo "Sequential:" | tee -a $RESULTS_FILE
    ./build/sequential_sort $SIZE | tee -a $RESULTS_FILE
    
    echo "" | tee -a $RESULTS_FILE
    echo "Pthreads ($THREADS threads):" | tee -a $RESULTS_FILE
    ./build/pthread_sort $SIZE $THREADS | tee -a $RESULTS_FILE
    
    echo "" | tee -a $RESULTS_FILE
    echo "OpenMP ($THREADS threads):" | tee -a $RESULTS_FILE
    ./build/openmp_sort $SIZE $THREADS | tee -a $RESULTS_FILE
    
    echo "" | tee -a $RESULTS_FILE
    echo "========================================" | tee -a $RESULTS_FILE
    echo "" | tee -a $RESULTS_FILE
done

echo "Benchmarking complete! Results saved to $RESULTS_FILE"











